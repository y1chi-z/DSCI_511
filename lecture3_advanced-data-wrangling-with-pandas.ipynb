{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dsci511_header.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Advanced data wrangling with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulate strings in Python with methods like `find`, `replace` and `join`.\n",
    "- Access string methods in Pandas via `Series.str`.\n",
    "- Understand how to use regular expressions in Pandas for wrangling strings.\n",
    "- Differentiate between datetime object in Pandas such as `Timestamp`, `Timedelta`, `Period`, `DateOffset`.\n",
    "- Create these datetime objects with functions like `pd.Timestamp()`, `pd.Period()`, `pd.date_range()`, `pd.period_range()`.\n",
    "- Index a datetime index with partial string indexing.\n",
    "- Perform basic datetime operations like splitting a datetime into constituent parts (e.g., `year`, `weekday`, `second`, etc), apply offsets, change timezones, and resample with `.resample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings\n",
    "\n",
    "Strings are a core data type in Python used for text-based data. They are enclosed in single (`'`) or double (`\"`) quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = 'I love Python!'\n",
    "double = \"I love Data Science!\"\n",
    "single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes our strings may themselves contain quotation marks or apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "single = 'That's weird' \n",
    "# raises error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a backlash `\\` (called an escape character) to prevent Python from interpreting `'` as a string delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = 'That\\'s weird'\n",
    "single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also have strings that contain backslashes, so you need to tell Python not to treat them as escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'Documents\\\\Lecture1'\n",
    "path2 = r'Documents\\Lecture1\\solutions.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating Strings\n",
    "\n",
    "- Strings can be concatenated using the `+` operator.\n",
    "- The `len()` function returns the length of a string, i.e. the number of characters it contains.\n",
    "- Use the `lower()`, `upper()` and `capitalize()` methods for case conversion.\n",
    "- You can remove leading and trailing whitespace from strings using `strip()`, `lstrip()`, and `rstrip()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = 'florence'\n",
    "last = 'nightingale'\n",
    "first + last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullname = '  Florence Nightingale      '\n",
    "fullname.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A whitespace character is any character that is displayed as \"blank space\" when text is rendered for display. Usual spaces and tabs (`'t'`)  are both whitespace characters. You might also frequently encounter new line characters (`'\\n'`), which force line breaks. Less commonly used whitespace characters are carriage returns, vertical tabs, and form feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substrings, Splitting and Joining\n",
    "\n",
    "- You can slice a string using integer indexing.\n",
    "- The `find()` and `index()` methods help you locate substrings.\n",
    "- The `replace()` method allows you to replace occurences of one substring with another.\n",
    "- The `split()` method splits one string into a list of substrings based on a delimiter\n",
    "- The `join()` method joins a list of strings into one, using a specified delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The-University-of-British-Columbia'\n",
    "text.find('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[1:].find('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.find('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.replace('-',' ') # Note this returns a new string, and does not modify the original in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split('-')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatted Strings\n",
    "\n",
    "Python can \"fill in the blanks\" using specified input to create strings. One way of doing this is using f-strings. These are useful when you want to print statements including variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 12\n",
    "print(f\"There are {num} months in a year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `print()` function above has some useful options that you can find in the Python documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using String Methods in Pandas\n",
    "\n",
    "In previous lectures, we saw that Pandas can apply arithmetic operations on an entire Series object \"all at once\". We can do the same for text data using `Series.str` which gives us access to the string methods we have seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('data/imdb.csv')\n",
    "imdb['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = imdb['Genre'].str.split(',', expand = True)\n",
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice there's some whitespace in the resulting columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.loc[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres[1] = genres[1].str.strip()\n",
    "genres.loc[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many string methods available to use in pandas. A full list is available in the [documentation](https://pandas.pydata.org/docs/user_guide/text.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expressions or REGEX\n",
    "\n",
    "- A regular expression (regex) is a sequence of characters that defines a search pattern.\n",
    "- Regex can do some truly magical things, so keep it in mind for complicated text wrangling!\n",
    "- Regex can also be difficult to get right, but there are many online tools (e.g. [RegExr](https://regexr.com)) that can help you find the correct patterns.\n",
    "\n",
    "You will learn more about regex in DSCI 521, so you don't need to learn it now. Here, just as an example, we use regex can find all movie titles in our IMDB dataset that start with a vowel and end with a consonant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findpattern = imdb['Series_Title'].str.findall(r'^[AEIOU].*[^aeiou]$')\n",
    "findpattern.loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down that regex:\n",
    "\n",
    "- The leading `^` specifies the start of a string.\n",
    "- Square brackets match a single character, so `[AEIOU]` is saying we want the first character to be a vowel.\n",
    "- `.` matches any character and `*` means '0 or more times', so `.*` will match any number of any characters in the middle of our string\n",
    "- Having a `^` inside and at the start of square brackets indicates a \"not\" and `$` matches the end of a string. So `[^aeiou]$` means we don't want the *last* character to be a vowel.\n",
    "\n",
    "We could have used regex to split the genres as well, which would allow us to specify a greater number of possible delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['Genre'].str.split('[,:.!]', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many `DataFrame.str()` methods accept regular expression as default, but you don't have to use regex if you don't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['Genre'].str.contains('ri', regex=False) # This tests for exact matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data\n",
    "\n",
    "Data Scientists often work with \"time series\" data, i.e. data that is indexed by time periods. We will breifly introduce time series in pandas here; you will encounter them much more in DSCI 574.\n",
    "\n",
    "Pandas provides several datetime objects, including:\n",
    "\n",
    "* Timestamp\n",
    "* Timedelta\n",
    "* Period\n",
    "* DateOffset\n",
    "\n",
    "We explore a few of them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Datetimes\n",
    "\n",
    "Most commonly you will want to\n",
    "\n",
    "- Create a single point in time with `pd.Timestamp()`.\n",
    "- Create a span of time with `pd.Period()`.\n",
    "- Create an array of times with `pd.date_range()` or `pd.period_range()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp('July 29, 2005') # parsed from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(year = 2005, month = 7, day = 9) # pass data directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have a specific point in time. We can use `pd.Period()` to specify a span of time (like a day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = pd.Period('2005-07-09')\n",
    "print(span)\n",
    "print(span.start_time)\n",
    "print(span.end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas understands when a `Timestamp` lies within a `Period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = pd.Timestamp('2005-07-09 12:00')\n",
    "span = pd.Period('2005-07-09')\n",
    "print(f'Point: {point}')\n",
    "print(f' Span: {span}')\n",
    "print(f'Point in span? {span.start_time < point < span.end_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, you will want to create **arrays** of datetimes, not just single values. In pandas, these come in the form of a `DatetimeIndex`, `PeriodIndex` or `TimedeltaIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('2020-09-01 12:00',\n",
    "              '2020-09-11 12:00',\n",
    "              freq='2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.period_range('2020-09-01',\n",
    "                '2020-09-11',\n",
    "                freq='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Timedelta` to add or subtract time from a `DatetimeIndex` or `PeriodIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range('2020-09-01 12:00', '2020-09-11 12:00', freq='D') + pd.Timedelta('1.5 hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, pandas represents missing datetimes with `NaT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Existing Data\n",
    "\n",
    "It's fairly common to have an array of dates as strings. We can use `pd.to_datetime()` to convert these to a datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling = pd.read_csv('data/cycling_data.csv')\n",
    "cycling.head() # Date column will be read in as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling['Date'] = pd.to_datetime(cycling['Date'])\n",
    "cycling['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually tell pandas to do this within the `read_csv` statement. Let's also set the datetime as the Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling = pd.read_csv('data/cycling_data.csv',\n",
    "                      parse_dates=True,\n",
    "                      index_col = 0)\n",
    "cycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing Datetimes\n",
    "\n",
    "Datetime index objects are just like regular index objects and can be selected, sliced, filtered etc. We can do **partial string indexing** to select datetimes within a certain range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.loc['2019-10'] # All logs for Oct 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exact** matching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.loc['2019-10-10 00:10:31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **slicing**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "cycling.loc['2019-10-01':'2019-10-13'] # raises error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oops, that failed. The error suggests the index might not be sorted (i.e. it may not be monotonic). Let's fix that and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.sort_index().loc['2019-10-01':'2019-10-13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting all results between a certain time of day (potentially on different days) we can use `df.between_time()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.between_time('00:00', '01:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Datetimes\n",
    "\n",
    "For more complex filtering, we may have to **decompose** our timeseries. There are many methods and attributes that we can access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.index.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.index.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.index.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.index.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're acting on a Series instead of a DatetimeIndex, you can access these methods using `.dt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "s = pd.Series(pd.date_range('2011-12-29', '2011-12-31'))\n",
    "s.year  # raises error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling and Aggregating\n",
    "\n",
    "One of the most common operations you will want do when working with time series is resampling to a coarser/finer/regular resolution. For example, you may want to resample daily data to weekly data.\n",
    "\n",
    "We can do that with the `.resample()` method. For example, let's resample the irregular cycling timeseries to a regular 12-hourly series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.resample('1D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `'1D'` is telling pandas to sample once daily. The letter `D` is the alias for the Daily offset, some other commonly used ones include\n",
    "\n",
    "* `'h'`, `'min'` and `'s'` for hours, minutes,  and seconds (resp.)\n",
    "* `'B'` for business day\n",
    "* `'MS'` and `'ME'` for month start and month end (resp.)\n",
    "\n",
    "A more complete list is available [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).\n",
    "\n",
    "Let's examine this `Resampler` object a little more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.resample('2D').groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output isn't so decipherable, but our data has been aggregated into *groups*. Since some groups have more than one entry, we need to tell pandas what to do with these. One option is to apply `mean()` to get an aggregated summary for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = cycling[[\"Time\",\"Distance\"]].resample('1D').mean()\n",
    "dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's quite a few `NaN`s in there. Some days do not have any data points-- we can choose how to handle these using `fillna` (for example, we could fill 0 distance and 0 time).\n",
    "\n",
    "The resampled index still has much of the same functionality we have seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr['Weekday'] = dfr.index.day_name()\n",
    "dfr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will study aggregate objects in pandas more thoroughly in Lecture 4, when we study the `groupby()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data\n",
    "\n",
    "What is categorical data? A categorical variable takes on a limited, and usually fixed, number of possible values. Examples are gender, social class, blood type, country affiliation, observation time or rating via Likert scales.\n",
    "\n",
    "What is a Pandas categorical data type? Internally, the data structure consists of a `categories` array and an integer array of `codes` which point to the real value in the `categories` array.\n",
    "\n",
    "Why use Pandas categoricals?\n",
    "\n",
    "- They allow categories to be ordered, which is useful for mapping attributes like color or size to category levels in plots.\n",
    "- They reduce memory usage and improve performance by storing repeated values more efficiently.\n",
    "- They improve the performance of certain operations, such as groupby and sorting, by leveraging the categorical nature of the data.\n",
    "\n",
    "*Source: <https://pandas.pydata.org/docs/user_guide/categorical.html>*\n",
    "\n",
    "#### Examples of categorical data in Pandas\n",
    "\n",
    "Let's load in `bean.csv` from the `data` directory. This file contains a small sample of a dataset from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/602/dry+bean+dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean = pd.read_csv('data/bean.csv')\n",
    "bean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There 18 columns in the dataset. Most are numerical, but the last column contains text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column of text data could have any number of distinct entries-- potentially each one could be different. Let's check how many unique entries this column contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean['Class'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 7 possibilities! As it turns out, they correspond to different classes of beans.\n",
    "\n",
    "Pandas has a `category` data type for columns where the variable takes one of a small (usually fixed) number of categories. We can convert existing columns from `object` to `category` dtype as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean['Class'] = bean['Class'].astype('category')\n",
    "bean['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean['Class'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look up the categories of a column by accessing the `Series.cat.categories` attribute. So to see the categories of the new 'Class' column, write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean['Class'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having categorical data is really useful for data vizualization. For example, we can plot bean length and width on the x and y axes (resp.) of a plot, and colour each data point based on the class it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(bean).mark_point().encode(\n",
    "    x='MajorAxisLength',\n",
    "    y='MinorAxisLength',\n",
    "    color=alt.Color('Class', scale=alt.Scale(scheme='category10')),\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the beans form clusters based on length and width!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to change the order the colours were assigned to our categories? The default is alphabetical. We could do this to change to reverse alphabetical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_order = sorted(bean['Class'].unique(), reverse=True)\n",
    "category_order\n",
    "# Convert 'species' column to a categorical type with the specified order\n",
    "bean['Class'] = pd.Categorical(bean['Class'], categories=category_order, ordered=True)\n",
    "bean['Class'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will our plot look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(bean).mark_point().encode(\n",
    "    x='MajorAxisLength',\n",
    "    y='MinorAxisLength',\n",
    "    color=alt.Color('Class', scale=alt.Scale(scheme='category10'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load another dataset that contains data about book sales on Amazon by reading in `data/publishers.csv`. This data was sourced from [CORGIS](https://corgis-edu.github.io/corgis/csv/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pd.read_csv('data/publishers.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row contains information on a particular book (although for some reason the dataset omits the book's title and author!) Let's see how many unique entries are contained in the `'publisher.type'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub['publisher.type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only four categories, and they have a natural ordering among them. We may want to sort our dataset based on the 'size' of the publisher-- but our column is an `object` dtype and contains strings. Strings are sorted alphabetically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pub.sort_values(by = 'publisher.type', ascending = False)\n",
    "print(pub.iloc[0]['publisher.type']) # Check the first row\n",
    "print(pub.iloc[240]['publisher.type']) # Somewhere in the middle\n",
    "print(pub.iloc[440]['publisher.type']) # Somewhere else in the middle\n",
    "print(pub.iloc[-1]['publisher.type']) # Check the last row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That sort wasn't useful here. Pandas categories, in contrast to strings, can be given any order we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub['publisher.type'] = pub['publisher.type'].astype('category')\n",
    "pub['publisher.type'] = (pub['publisher.type'].cat.reorder_categories(\n",
    "                                ['single author', 'indie', 'small/medium', 'big five'], ordered=True)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pub.sort_values('publisher.type', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pub.iloc[0]['publisher.type']) # Check the first row\n",
    "print(pub.iloc[240]['publisher.type']) # Somewhere in the middle\n",
    "print(pub.iloc[440]['publisher.type']) # Somewhere in the middle\n",
    "print(pub.iloc[-1]['publisher.type']) # Check the last row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Frame also contains a column called `'genre'`. That's another candidate for categorical data, so let's see what unique values it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, looks like two spellings (`'comics'` and `'Comics'`) are listed for the same genre! This is a common occurrence. In general, it is best to do your data wrangling first and only convert to the `category` dtype once your data is cleaned up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
